# Vivado Flow - HBM Performance Analysis on FPGA

## Overview

This section of the repository focuses on the Vivado design flow used in the MSc thesis project "Performance Analysis of HBM Memory on Reconfigurable Devices Using Different Design Flows." The design in this flow was realized using Vivado block integration. The primary objective was to measure the High Bandwidth Memory (HBM) bandwidth using a simple custom IP developed in VHDL.

## Folder Structure

- **ip_repo**: This folder contains the two custom IPs, krnl_axi (the HLS IP) and LatencyCounter, which are essential for the design.

- **scripts**: In this directory, you'll find several shell scripts. These scripts are designed to run tests and utilize the dma_ip_drivers-2020.1 of the XDMA to control and interact with the custom IPs by writing to their registers.

- **constraints.xdc**: The Xilinx Design Constraints (XDC) file that specifies the constraints for the design, ensuring proper signal routing and timing considerations.

- **design_1_wrapper.v**: The design wrapper file that encapsulates the entire design.

- **block_design.pdf**: This PDF file contains the final block design, providing a visual representation of the design architecture within Vivado.

- **HBM31Master.tcl**: This TCL script can be executed in Vivado 2020.1 to recreate the Vivado project. It can be used for project setup and regeneration.

## Design Elements

### Custom IPs

1. **krnl_axi (HLS IP)**: This custom IP, realized using High-Level Synthesis (HLS) in order to simply use it in both design flows, plays a central role in reading and writing data from/to the HBM.

2. **LatencyCounter**: In this Vivado flow, a custom IP called LatencyCounter was used to calculate the HBM bandwidth. This IP is essentially a counter with start and stop signals. The start signal is driven by the axvalid signal of the AXI protocol, while the end signal is generated by the HLS IP.

### Design Recap

In the final block design:

- The **Clocking Wizard** provides the required clocks for the design.
- The **XDMA** IP connects to all the krnl_axi IPs, all the LatencyCounter IPs, and one port of the HBM. It facilitates FPGA execution from the host system.
- The **krnl_axi IPs** operate at 250 MHz and use a 512-bit data bus to interface with the HBM, optimizing timing closure.
- **LatencyCounter IPs** count clock cycles between the start and end signals, which are triggered by AXI_awvalid and AXI_arvalid signals and the interrupt signal of krnl_axi, respectively.
- The **HBM IP** is directly connected to the krnl_axi IPs for read or write operations on the HBM.

### Timing Adjustments

In the pursuit of achieving the maximum HBM bandwidth, a series of strategic adjustments were made in the custom design to meet timing requirements while maintaining optimal performance. These adjustments were necessary to manage the complexities of high-frequency designs and ensure the efficient operation of the system. Here, we summarize the key timing adjustments made:

1. **Frequency Limitation**: To reach a 450 MHz frequency on the AXI interfaces of the controller, adjustments were made to manage high frequencies efficiently. The high frequency of 450 MHz was applied only where strictly necessary to maximize HBM bandwidth.

2. **Clock Management**: Different clock domains were used for various components. A slower clock was employed for time measurement in the LatencyCounter IP. The clock generated by the XDMA was adopted as the AXI clock to configure the IPs.

3. **Increased Data Width**: To ensure that the kernels could run using a slower clock without impacting performance, the AXI data width was increased. This adjustment counterbalanced the slower clock frequency.

4. **Pipeline Registers**: The use of pipeline registers was employed strategically. These registers played a crucial role in meeting timing requirements, especially in scenarios where the path between the AXI Master and the AXI Slave became lengthy and could not be covered within a single clock period.

5. **Asynchronous Clock Domains**: By default, Vivado assumes that all clock domains are synchronous and related. To ease the timing constraints, the design indicated that the clocks leaving the clk_wizard are asynchronous with the clock emerging from the XDMA.

6. **Implementation Strategy**: The implementation strategy employed by Vivado during the implementation phase can greatly influence timing results. In this design, the "Performance_ExploreWithRemap" strategy was used. This approach led to multiple optimization passes and attempted to remap the Look-Up Tables (LUTs) in the design to reduce logic levels, ultimately improving timing results.

These adjustments collectively played a pivotal role in ensuring that the custom design met timing requirements while striving for the highest possible HBM bandwidth.

## How to Install and Run the Application

To get started with running the application and testing the design, follow these steps:

### Prerequisites

- Ensure you have Xilinx Vivado 2020.1.
- Make sure you have an Xilinx Alveo U280 FPGA.
- You will need the Xilinx PCIe DMA drivers installed on your host system.

### Installation Steps

1. **Clone the Repository**: First, clone this repository to your local machine. You can use the following command in your terminal:

   ```shell
   git clone https://github.com/lucavivenzo/HBM-Performance-Analysis-FPGA
   ```

2. **Launch the Vivado TCL Script**:
   - Navigate to the HBM-Vivado directory of the cloned repository.
   - Execute the `HBM31Master.tcl` script in Vivado 2020.1 using the following command:

     ```shell
     cd HBM-Performance-Analysis-FPGA/HBM-Vivado
     vivado -mode batch -source HBM31Master.tcl
     ```

   This script will set up the Vivado project and configure the design.

3. **Run Synthesis and Implementation**:
   - Open the Vivado project that was created in the previous step.
   - Perform synthesis and implementation for your design within the Vivado environment.

4. **Generate the Bitstream**:
   - After synthesis and implementation are successful, generate the bitstream for your design.

5. **Upload Bitstream to FPGA**:
   - Use Xilinx tools or the provided scripts to upload the generated bitstream to your Xilinx Alveo U280 FPGA.

6. **Rescan PCIe Devices:**
   - After uploading the bitstream to the FPGA, rescan the PCIe devices on your host system to ensure the newly configured FPGA is detected. You can typically use the lspci command to verify that the FPGA device is recognized.

7. **Install Xilinx PCIe DMA Drivers**:
   - Ensure that the Xilinx PCIe DMA drivers (dma_ip_drivers-2020.1 or compatible version) are installed on your host system to pilot the IPs by writing on their registers.

8. **Launch the Scripts**:
   - In the `scripts` directory of the repository, you will find shell scripts for running tests and interacting with the custom IPs. Execute these scripts as needed.

### Usage

You are now ready to use the application. The scripts in the `scripts` directory will help you test the design, measure HBM bandwidth, and assess the performance of your application on the FPGA.

If you have any questions or encounter issues during the installation or execution, please don't hesitate to contact the author(s) for assistance.

---

This section provides step-by-step instructions on how to clone the repository, set up the application using Vivado 2020.1, upload the bitstream to the FPGA, install necessary drivers, and run the scripts for testing and performance analysis.
